{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from duckduckgo_search import DDGS\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading Company Names from dataset.\n",
    "###### You can ask Company Names from user inputs and search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"company_names.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fetching the first url obtained after searching each Company Names.\n",
    "###### I've used duckduckgo API as it doesn't require API key or CSE ID. You can use other APIs like Google Custom Search API or googlesearch or BeautifulSoup llibraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_link(query):\n",
    "    time.sleep(1)     #add delays to avoid triggering rate limits\n",
    "    with DDGS() as ddgs:\n",
    "        results = list(ddgs.text(query, max_results=1))\n",
    "        return results[0][\"href\"] if results else None\n",
    "\n",
    "df['First_Link'] = df['Company Names'].apply(get_first_link)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Common suffixes in company name to ignore.\n",
    "###### These suffixes disturbs the verification logic as it gets included while fetching the initials of company names or while the comparing the company name with urls(relate when verification logic will be explained below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common suffixes to ignore\n",
    "exclude_words = {\n",
    "    \"inc\", \"in\", \"inc.\", \"llc\", \"llc.\", \"ltd\", \"ltd.\", \"co\", \"co.\", \"corp\", \"corp.\", \"company\", \"corporation\",\n",
    "    \"plc\", \"plc.\", \"gmbh\", \"s.a.\", \"s.a.s.\", \"s.r.l.\", \"b.v.\", \"n.v.\", \"pvt\", \"pvt.\", \"pte\", \"pte.\",\n",
    "    \"limited\", \"llp\", \"llp.\", \"lp\", \"lp.\", \"sa\", \"ag\", \"oy\", \"ab\", \"as\", \"sarl\", \"k.k.\", \"s.p.a.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verifying if the obtained url is the link for official website of the Company with either of the 3 Conditions.\n",
    "######  First: Check if the company name is fully present in the domain name.\n",
    "######  Second: Check if the first word of the Company's Name is present in the domain name, excluding the suffixes.\n",
    "######  Third: Check if the initials of the Company's Name are present in the domain name, in exact order excluding the suffixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    #Remove special characters (-, _, ., etc.) and convert to lowercase\n",
    "    return re.sub(r'[^a-zA-Z0-9\\s]', ' ', str(text)).lower().strip()\n",
    "\n",
    "def extract_initials(company_name):\n",
    "    #Extract initials from the company name while ignoring common suffixes\n",
    "    words = clean_text(company_name).split()\n",
    "    filtered_words = [word for word in words if word not in exclude_words]  #Remove unwanted words\n",
    "    return \"\".join(word[0] for word in filtered_words)  #Take the initials of each word\n",
    "\n",
    "def generate_word_list(company_name):\n",
    "    #Generate a list of individual words from the company name, excluding common suffixes\n",
    "    return list(word for word in clean_text(company_name).split() if word not in exclude_words)\n",
    "\n",
    "def extract_domain(url):\n",
    "    #Extract the main domain name from fetched urls\n",
    "    if pd.isna(url):\n",
    "        return \"\"\n",
    "    return urlparse(url).netloc.replace(\"www.\", \"\").split('.')[0]  #Extract domain part only\n",
    "\n",
    "def is_official_website(company, url):\n",
    "    if pd.isna(url) or not url.strip():\n",
    "        return \"No Website\"\n",
    "\n",
    "    domain = extract_domain(url)\n",
    "    company_names_cleaned = clean_text(company)\n",
    "    company_names_words = generate_word_list(company)\n",
    "    company_names_initials = extract_initials(company)\n",
    "\n",
    "    # Condition 1. Exact Match\n",
    "    if company_names_cleaned in domain:\n",
    "        return url\n",
    "\n",
    "    # Condition 2. Check if the first word from company name exists in domain\n",
    "    if company_names_words[0] in domain:\n",
    "        return url\n",
    "\n",
    "    # Condition 3. Check if initials appear as a substring in exact order\n",
    "    if company_names_initials and company_names_initials in domain:\n",
    "        return url\n",
    "\n",
    "    return \"No Website\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validating the fetched links with verification logics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Result\"] = df.apply(lambda row: is_official_website(row[\"Company Names\"], row[\"First_Link\"]), axis=1)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract the required data to a new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=df[['Company Names','Result']]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Export the required data from output to excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_excel('Official_Websites.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
